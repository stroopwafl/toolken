{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "output-file: tokenizer.html\n",
    "title: Tokenizer\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- WARNING: THIS FILE WAS AUTOGENERATED! DO NOT EDIT! -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/stroopwafl/toolken/blob/main/toolken/tokenizer.py#L15){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### Tokenizer\n",
       "\n",
       ">      Tokenizer (model_path:str)\n",
       "\n",
       "Initialize self.  See help(type(self)) for accurate signature."
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/stroopwafl/toolken/blob/main/toolken/tokenizer.py#L15){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### Tokenizer\n",
       "\n",
       ">      Tokenizer (model_path:str)\n",
       "\n",
       "Initialize self.  See help(type(self)) for accurate signature."
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(Tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/stroopwafl/toolken/blob/main/toolken/tokenizer.py#L45){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### encode_to_tensor\n",
       "\n",
       ">      encode_to_tensor (tokenizer, prompt:[typing.List[str],<class'str'>],\n",
       ">                        eos=True)"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/stroopwafl/toolken/blob/main/toolken/tokenizer.py#L45){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### encode_to_tensor\n",
       "\n",
       ">      encode_to_tensor (tokenizer, prompt:[typing.List[str],<class'str'>],\n",
       ">                        eos=True)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(encode_to_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/stroopwafl/toolken/blob/main/toolken/tokenizer.py#L50){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### decode_tokens\n",
       "\n",
       ">      decode_tokens (tokenizer, tokens, prompt_tokens, max_gen_len)"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/stroopwafl/toolken/blob/main/toolken/tokenizer.py#L50){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### decode_tokens\n",
       "\n",
       ">      decode_tokens (tokenizer, tokens, prompt_tokens, max_gen_len)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(decode_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7487e0b-c4a7-4c2e-89db-9d238222d340",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "main_env",
   "language": "python",
   "name": "main_env"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
