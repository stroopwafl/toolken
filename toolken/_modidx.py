# Autogenerated by nbdev

d = { 'settings': { 'branch': 'main',
                'doc_baseurl': '/toolken',
                'doc_host': 'https://stroopwafl.github.io',
                'git_url': 'https://github.com/stroopwafl/toolken',
                'lib_path': 'toolken'},
  'syms': { 'toolken.core': { 'toolken.core.get_device': ('core.html#get_device', 'toolken/core.py'),
                              'toolken.core.plot_images': ('core.html#plot_images', 'toolken/core.py')},
            'toolken.datasets': { 'toolken.datasets.DataLoaders': ('datasets.html#dataloaders', 'toolken/datasets.py'),
                                  'toolken.datasets.DataLoaders.__init__': ('datasets.html#dataloaders.__init__', 'toolken/datasets.py'),
                                  'toolken.datasets.PromptDS': ('datasets.html#promptds', 'toolken/datasets.py'),
                                  'toolken.datasets.PromptDS.__getitem__': ('datasets.html#promptds.__getitem__', 'toolken/datasets.py'),
                                  'toolken.datasets.PromptDS.__init__': ('datasets.html#promptds.__init__', 'toolken/datasets.py'),
                                  'toolken.datasets.PromptDS.__len__': ('datasets.html#promptds.__len__', 'toolken/datasets.py')},
            'toolken.inference': { 'toolken.inference.add': ('inference.html#add', 'toolken/inference.py'),
                                   'toolken.inference.complete_function_call': ( 'inference.html#complete_function_call',
                                                                                 'toolken/inference.py'),
                                   'toolken.inference.decode_toolken': ('inference.html#decode_toolken', 'toolken/inference.py'),
                                   'toolken.inference.divide': ('inference.html#divide', 'toolken/inference.py'),
                                   'toolken.inference.format_args': ('inference.html#format_args', 'toolken/inference.py'),
                                   'toolken.inference.generate': ('inference.html#generate', 'toolken/inference.py'),
                                   'toolken.inference.multiply': ('inference.html#multiply', 'toolken/inference.py'),
                                   'toolken.inference.sample': ('inference.html#sample', 'toolken/inference.py'),
                                   'toolken.inference.subtract': ('inference.html#subtract', 'toolken/inference.py')},
            'toolken.model': { 'toolken.model.Attention': ('model.html#attention', 'toolken/model.py'),
                               'toolken.model.Attention.__init__': ('model.html#attention.__init__', 'toolken/model.py'),
                               'toolken.model.Attention.forward': ('model.html#attention.forward', 'toolken/model.py'),
                               'toolken.model.FeedForward': ('model.html#feedforward', 'toolken/model.py'),
                               'toolken.model.FeedForward.__init__': ('model.html#feedforward.__init__', 'toolken/model.py'),
                               'toolken.model.FeedForward.forward': ('model.html#feedforward.forward', 'toolken/model.py'),
                               'toolken.model.FunctionModel': ('model.html#functionmodel', 'toolken/model.py'),
                               'toolken.model.FunctionModel.__init__': ('model.html#functionmodel.__init__', 'toolken/model.py'),
                               'toolken.model.FunctionModel.forward': ('model.html#functionmodel.forward', 'toolken/model.py'),
                               'toolken.model.FunctionModel.init_grads': ('model.html#functionmodel.init_grads', 'toolken/model.py'),
                               'toolken.model.FunctionModel.set_bias': ('model.html#functionmodel.set_bias', 'toolken/model.py'),
                               'toolken.model.LoRA': ('model.html#lora', 'toolken/model.py'),
                               'toolken.model.LoRA.__init__': ('model.html#lora.__init__', 'toolken/model.py'),
                               'toolken.model.LoRA.forward': ('model.html#lora.forward', 'toolken/model.py'),
                               'toolken.model.LoRA.reset_lora_parameters': ('model.html#lora.reset_lora_parameters', 'toolken/model.py'),
                               'toolken.model.LoRA.upgrade_state_dict_named': ( 'model.html#lora.upgrade_state_dict_named',
                                                                                'toolken/model.py'),
                               'toolken.model.ModelArgs': ('model.html#modelargs', 'toolken/model.py'),
                               'toolken.model.RMSNorm': ('model.html#rmsnorm', 'toolken/model.py'),
                               'toolken.model.RMSNorm.__init__': ('model.html#rmsnorm.__init__', 'toolken/model.py'),
                               'toolken.model.RMSNorm._norm': ('model.html#rmsnorm._norm', 'toolken/model.py'),
                               'toolken.model.RMSNorm.forward': ('model.html#rmsnorm.forward', 'toolken/model.py'),
                               'toolken.model.Transformer': ('model.html#transformer', 'toolken/model.py'),
                               'toolken.model.Transformer.__init__': ('model.html#transformer.__init__', 'toolken/model.py'),
                               'toolken.model.Transformer.forward': ('model.html#transformer.forward', 'toolken/model.py'),
                               'toolken.model.TransformerBlock': ('model.html#transformerblock', 'toolken/model.py'),
                               'toolken.model.TransformerBlock.__init__': ('model.html#transformerblock.__init__', 'toolken/model.py'),
                               'toolken.model.TransformerBlock.forward': ('model.html#transformerblock.forward', 'toolken/model.py'),
                               'toolken.model.apply_rotary_emb': ('model.html#apply_rotary_emb', 'toolken/model.py'),
                               'toolken.model.precompute_freqs_cis': ('model.html#precompute_freqs_cis', 'toolken/model.py'),
                               'toolken.model.reshape_for_broadcast': ('model.html#reshape_for_broadcast', 'toolken/model.py'),
                               'toolken.model.sample_top_p': ('model.html#sample_top_p', 'toolken/model.py'),
                               'toolken.model.setup_model_parallel': ('model.html#setup_model_parallel', 'toolken/model.py')},
            'toolken.tokenizer': { 'toolken.tokenizer.Tokenizer': ('tokenizer.html#tokenizer', 'toolken/tokenizer.py'),
                                   'toolken.tokenizer.Tokenizer.__init__': ('tokenizer.html#tokenizer.__init__', 'toolken/tokenizer.py'),
                                   'toolken.tokenizer.Tokenizer.decode': ('tokenizer.html#tokenizer.decode', 'toolken/tokenizer.py'),
                                   'toolken.tokenizer.Tokenizer.encode': ('tokenizer.html#tokenizer.encode', 'toolken/tokenizer.py'),
                                   'toolken.tokenizer.decode_tokens': ('tokenizer.html#decode_tokens', 'toolken/tokenizer.py'),
                                   'toolken.tokenizer.encode_to_tensor': ('tokenizer.html#encode_to_tensor', 'toolken/tokenizer.py')},
            'toolken.train': { 'toolken.train.Trainer': ('train.html#trainer', 'toolken/train.py'),
                               'toolken.train.Trainer.__init__': ('train.html#trainer.__init__', 'toolken/train.py'),
                               'toolken.train.Trainer.calculate_results': ('train.html#trainer.calculate_results', 'toolken/train.py'),
                               'toolken.train.Trainer.make_storage': ('train.html#trainer.make_storage', 'toolken/train.py'),
                               'toolken.train.Trainer.print_epoch_results': ('train.html#trainer.print_epoch_results', 'toolken/train.py'),
                               'toolken.train.Trainer.save_embeddings': ('train.html#trainer.save_embeddings', 'toolken/train.py'),
                               'toolken.train.Trainer.save_results': ('train.html#trainer.save_results', 'toolken/train.py'),
                               'toolken.train.Trainer.train_embeddings': ('train.html#trainer.train_embeddings', 'toolken/train.py')}}}
