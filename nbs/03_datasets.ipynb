{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "277886b1-48db-4db1-8195-764b9d72566a",
   "metadata": {},
   "source": [
    "# Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b719fed-9fe2-4fc7-8b71-a6de1292bac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f5405f-20ac-4243-b358-9709c6b50c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from __future__ import annotations\n",
    "import math, random, torch, matplotlib.pyplot as plt, numpy as np, matplotlib as mpl, shutil, os, gzip, pickle, re, copy, time\n",
    "from pathlib import Path\n",
    "from functools import partial\n",
    "import fastcore.all as fc\n",
    "from glob import glob\n",
    "import json\n",
    "\n",
    "from torch import tensor, nn, optim\n",
    "import torch.nn.functional as F\n",
    "from datasets import load_dataset\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import DataLoader, default_collate\n",
    "from torch.nn import init\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from typing import List, Optional\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "import calendar\n",
    "from fastprogress import progress_bar\n",
    "from einops import rearrange\n",
    "\n",
    "from toolken.model import *\n",
    "from toolken.tokenizer import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f4c2b3-0541-400d-abc2-cef8d9f71f2d",
   "metadata": {},
   "source": [
    "### Build dataset\n",
    "\n",
    "I'm going to work with a single dataset for now — the GSM8K-XL math dataset for training the calculator tool. The dataset is provided by the original toolken authors in [this GitHub repo](https://github.com/Ber666/ToolkenGPT)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21177bcc-014d-4096-9ed9-91c36e21e795",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../model/tokenizer.model'\n",
    "tokenizer = Tokenizer(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84b874d-c14f-4cf9-bb00-3e241563adea",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/gsm8k-xl/train.json', 'r') as f: data = json.load(f)\n",
    "with open('../data/gsm8k-xl/func_dict.json', 'r') as f: func_dict = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee5b258-83ca-4117-b785-9a521e9522ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': \"Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May? Let's think step by step. Natalia sold 48/2 = 24 clips in May.\\nNatalia sold 48+24 = 72 clips altogether in April and May.\\n#### 72\",\n",
       " 'start_token_idx': [60, 80],\n",
       " 'end_token_idx': [62, 82],\n",
       " 'tar_eq': ['<divide>(48, 2)=24<eoe>', '<add>(48, 24)=72<eoe>'],\n",
       " 'tar_number': ['24', '72']}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4a3e99-8429-422b-a168-62190e2deec4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<add>': 0, '<subtract>': 1, '<multiply>': 2, '<divide>': 3}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "func_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c77f7f0-a7a3-4c43-9903-2da4e40c700b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class PromptDS:\n",
    "    def __init__(self, json, tokenizer, func_dict): fc.store_attr()\n",
    "    def __len__(self): return len(self.json)\n",
    "    def __getitem__(self, i): \n",
    "        item = self.json[i]\n",
    "        item['input'] = tensor(self.tokenizer.encode(item['text'], bos=True, eos=True))\n",
    "        item['label'] = tensor(self.tokenizer.encode(item['text'], bos=True, eos=True))\n",
    "        for i, idx in enumerate(item['start_token_idx']):\n",
    "            start, end = idx, item['end_token_idx'][i]\n",
    "            op = re.search(r\"(<.*?>)\", item['tar_eq'][i]).group(1)\n",
    "            item['label'][start] = self.func_dict[op] + 32000\n",
    "            item['label'][start+1:end] = -100\n",
    "        return item['input'], item['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942100cc-0870-48e0-89c0-dfcb7cfb9702",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class DataLoaders:\n",
    "    def __init__(self, tds, vds, bs, **kwargs): \n",
    "        self.train = DataLoader(tds, batch_size=bs, shuffle=True, collate_fn=default_collate, num_workers=4, **kwargs)\n",
    "        self.valid = DataLoader(vds, batch_size=bs, collate_fn=default_collate, num_workers=4, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93a594d-da3c-41bb-adb6-668fbc2184ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5448, 606)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tds = PromptDS(data[:int(0.9*len(data))], tokenizer, func_dict)\n",
    "vds = PromptDS(data[int(0.9*len(data)):], tokenizer, func_dict)\n",
    "len(tds), len(vds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f3b1612-98d2-41ee-8a2b-891b619cc31c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 98]), torch.Size([1, 98]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dls = DataLoaders(tds, vds, 1)\n",
    "inp, label = next(iter(dls.train))\n",
    "inp.shape, label.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd43ab5-277a-49aa-8114-0a1c3f5a11f9",
   "metadata": {},
   "source": [
    "The dataloader here is going to provide the model with an `input` and a `label`.\n",
    "\n",
    "The `input`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481905c9-12a6-4b61-8759-b93c9df3b0d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the school play, 40 rows of chairs were set up where there were 20 chairs in each row. If only 10 seats were not occupied, how many seats were taken? Let's think step by step. The school prepared 40 x 20 = 800 chairs.\n",
      "So, 800 - 10 = 790 chairs were taken.\n",
      "#### 790\n"
     ]
    }
   ],
   "source": [
    "a = tokenizer.decode(list([i.item() for i in inp[0]]))\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd4891f4-4ce2-4d95-9bff-fec2372392b7",
   "metadata": {},
   "source": [
    "The `label` is going to have the same structure as the input. However, the tokens in the input that represent an answer to a mathematical expression are going to be replaced by a new token that represents the operator required to calculate that result. Thus, the responsibility of the model is to, when faced with a mathematical expression, predict the operator token required to calculate that expression. Once the model is finetuned to do this, we'll do some additional processing in the inference method to formulate the arguments to be sent to an external calculator tool. In the case of other tools, the mechanism would be the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf95d87-328b-4cc9-8cbb-07d9fbcae59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = torch.ne(inp, label)\n",
    "m2 = torch.where(label == -100, True, False)\n",
    "m3 = torch.where(label >= 32000, True, False)\n",
    "l = torch.zeros_like(label)\n",
    "l[~m] = label[~m]\n",
    "lab = tokenizer.decode([i.item() for i in l[~m2]])\n",
    "r = [a.item()-32000 for a in label[m3]]\n",
    "for h in r: \n",
    "    op = [k for k,v in func_dict.items() if v == h]\n",
    "    lab = lab.replace(\"⁇\", op[0], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2b991e-c716-4906-b13b-b0d92d483ebb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the school play, 40 rows of chairs were set up where there were 20 chairs in each row. If only 10 seats were not occupied, how many seats were taken? Let's think step by step. The school prepared 40 x 20 =  <multiply>  chairs.\n",
      "So, 800 - 10 =  <subtract>  chairs were taken.\n",
      "#### 790\n"
     ]
    }
   ],
   "source": [
    "print(lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877b94fb-4acb-4605-bbdc-f4066e26e670",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a2a4095-452d-48ef-8937-9d351a90ef55",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "main_env",
   "language": "python",
   "name": "main_env"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
