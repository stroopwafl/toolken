{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e83b1b11-8651-4812-9d79-123f6694ad6b",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8815e536-f477-4af6-98a7-30dc8ed1bc60",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f823ee-53d9-4e2d-bce9-cdcf4ee19822",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from __future__ import annotations\n",
    "import math, random, torch, matplotlib.pyplot as plt, numpy as np, matplotlib as mpl, shutil, os, gzip, pickle, re, copy, time\n",
    "from pathlib import Path\n",
    "from functools import partial\n",
    "import fastcore.all as fc\n",
    "from glob import glob\n",
    "import json\n",
    "\n",
    "from torch import tensor, nn, optim\n",
    "import torch.nn.functional as F\n",
    "from datasets import load_dataset\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import DataLoader, default_collate\n",
    "from torch.nn import init\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from typing import List, Optional\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "import calendar\n",
    "from fastprogress import progress_bar\n",
    "from einops import rearrange\n",
    "\n",
    "from toolken.model import *\n",
    "from toolken.tokenizer import *\n",
    "from toolken.datasets import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2972807f-15a4-4fea-9e57-c669473f87ff",
   "metadata": {},
   "source": [
    "Inference is the same as inference in all language models, apart from 'tool mode'. When the next predicted token is a 'toolken' (a token that represents a function call), there is some additional processing to formulate arguments, carry out the function call and return the results to the generation. \"Tool mode\" is itself just a nested inference task — it involves prompting the model again to formulate the arguments.\n",
    "\n",
    "There are two prompt templates — one for the top-level task of answering the user input, and one for the nested task of formulating the arguments for the function call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69243bed-79b0-450d-9277-c5cf75cdb12f",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../data/gsm8k-xl/template'\n",
    "prompt_template = open(f'{path}/llama_general.txt').read()\n",
    "func_template = open(f'{path}/llama_func.txt').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a25c51-975a-4b26-871f-bcae61d8e4a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer the following questions step by step\n",
      "\n",
      "Question: Mark has 3 tanks for pregnant fish.  Each tank has 4 pregnant fish and each fish gives birth to 20 young.  How many young fish does he have at the end?\n",
      "Answer: He has 4*3=12 pregnant fish They give birth to 12*20=240 fish #### 240\n",
      "\n",
      "Question: The math questions in a contest are divided into three rounds: easy, average, and hard. There are corresponding points given for each round. That is 2, 3, and 5 points for every correct answer in the easy, average, and hard rounds, respectively. Suppose Kim got 6 correct answers in the easy; 2 correct answers in the average; and 4 correct answers in the difficult round, what are her total points in the contest?\n",
      "Answer: Kim got 6 points/round x 2 round = 12 points in the easy round. She got 2 points/round x 3 rounds = 6 points in the average round. She got 4 points/round x 5 rounds = 20 points in the difficult round. So her total points is 12 points + 6 points + 20 points = 38 points. #### 38\n",
      "\n",
      "Question: A clothing store sells 20 shirts and 10 pairs of jeans. A shirt costs $10 each and a pair of jeans costs twice as much. How much will the clothing store earn if all shirts and jeans are sold?\n",
      "Answer: Twenty shirts amount to $10 x 20 = $200. The cost of each pair of jeans is $10 x 2 = $20. So 10 pairs of jeans amount to $20 x 10 = $200. Therefore, the store will earn $200 + $200 = $400 if all shirts and jeans are sold. #### 400\n",
      "\n",
      "Question: Arnold's collagen powder has 18 grams of protein for every 2 scoops.  His protein powder has 21 grams of protein per scoop.  And his steak has 56 grams of protein.   If he has 1 scoop of collagen powder, 1 scoop of protein powder and his steak, how many grams of protein will he consume?\n",
      "Answer: 2 scoops of collagen powder have 18 grams of protein and he only has 1 scoop so he consumes 18/2 = 9 grams of protein He has 9 grams collagen powder, 21 grams of protein powder and 56 grams in his steak for a total of 9+21+56 = 86 grams of protein #### 86\n",
      "\n",
      "Question: [QUESTION]\n",
      "Answer:\n"
     ]
    }
   ],
   "source": [
    "print(prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121bf59b-5687-4353-9ade-e60a39cd3d1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer the following questions with <add>, <subtract>, <multiply>, <divide> operators\n",
      "\n",
      "Question: Mark has 3 tanks for pregnant fish.  Each tank has 4 pregnant fish and each fish gives birth to 20 young.  How many young fish does he have at the end?\n",
      "Answer: He has 4*3=<multiply>(4, 3)=12 pregnant fish They give birth to 12*20=<multiply>(12, 20)=240 fish #### 240\n",
      "\n",
      "Question: The math questions in a contest are divided into three rounds: easy, average, and hard. There are corresponding points given for each round. That is 2, 3, and 5 points for every correct answer in the easy, average, and hard rounds, respectively. Suppose Kim got 6 correct answers in the easy; 2 correct answers in the average; and 4 correct answers in the difficult round, what are her total points in the contest?\n",
      "Answer: Kim got 6 points/round x 2 round = <multiply>(6, 2)=12 points in the easy round. She got 2 points/round x 3 rounds = <multiply>(2, 3)=6 points in the average round. She got 4 points/round x 5 rounds = <multiply>(4, 5)=20 points in the difficult round. So her total points is 12 points + 6 points + 20 points = <add>(12, 6, 20)=38 points. #### 38\n",
      "\n",
      "Question: A clothing store sells 20 shirts and 10 pairs of jeans. A shirt costs $10 each and a pair of jeans costs twice as much. How much will the clothing store earn if all shirts and jeans are sold?\n",
      "Answer: Twenty shirts amount to $10 x 20 = $<multiply>(10, 20)=200. The cost of each pair of jeans is $10 x 2 = $<multiply>(10, 2)=20. So 10 pairs of jeans amount to $20 x 10 = $<multiply>(20, 10)=200. Therefore, the store will earn $200 + $200 = $<add>(200, 200)=400 if all shirts and jeans are sold. #### 400\n",
      "\n",
      "Question: Arnold's collagen powder has 18 grams of protein for every 2 scoops.  His protein powder has 21 grams of protein per scoop.  And his steak has 56 grams of protein.   If he has 1 scoop of collagen powder, 1 scoop of protein powder and his steak, how many grams of protein will he consume?\n",
      "Answer: 2 scoops of collagen powder have 18 grams of protein and he only has 1 scoop so he consumes 18/2 = <divide>(18, 2)=9 grams of protein He has 9 grams collagen powder, 21 grams of protein powder and 56 grams in his steak for a total of 9+21+56 = <add>(9, 21, 56)=86 grams of protein #### 86\n",
      "\n",
      "Question: [QUESTION]\n",
      "Answer:\n"
     ]
    }
   ],
   "source": [
    "print(func_template)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc66e40e-7140-4c13-ba24-3f08b00d9abf",
   "metadata": {},
   "source": [
    "The authors of the original Toolken paper helpfully provided a set of test cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4feab0d-2473-4024-9792-04e016db51c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../data/gsm8k-xl/test.json'\n",
    "test_data = [json.loads(line) for line in open(path).readlines()]\n",
    "raw_test_cases = [i[\"question\"] for i in test_data]\n",
    "enhanced_v = [i[\"enhanced_v\"] for i in test_data]\n",
    "test_cases = []\n",
    "for v, q in zip(enhanced_v, raw_test_cases):\n",
    "    for i in range(len(v)):\n",
    "        q = q.replace(f\"{{v_{i+1}}}\", str(v[i]))\n",
    "    test_cases.append(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eaa8d12-a511-4f33-9962-293943e7631d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Janet’s ducks lay 4096 eggs per day. She eats 27 for breakfast every morning and bakes muffins for her friends every day with 64. She sells the remainder at the farmers' market daily for $8 per fresh duck egg. How much in dollars does she make every day at the farmers' market?\""
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_cases[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81184c4a-27f7-47de-92ec-9d3b864c6882",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<add>': 0, '<subtract>': 1, '<multiply>': 2, '<divide>': 3}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = '../data/gsm8k-xl/func_dict.json'\n",
    "func_dict = json.load(open(path))\n",
    "func_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f9f192-f8c8-43a4-87c1-c1d6dc5cdb97",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def add(x,y): return x+y\n",
    "def subtract(x,y): return x-y\n",
    "def multiply(x,y): return x*y\n",
    "def divide(x,y): return x/y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac31df6-a84e-4c71-b2a7-d0cce6cca394",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def generate(self, model, prompt, temperature=0.8, top_p=0.95, max_len=512, stop_token=[]):\n",
    "    bsz = len(prompts)\n",
    "    params = model.params\n",
    "    assert bsz <= params.max_batch_size, (bsz, params.max_batch_size)\n",
    "    \n",
    "    prompt_tokens = [tokenizer.encode(x, bos=True, eos=False) for x in prompts]\n",
    "\n",
    "    min_prompt_size = min([len(t) for t in prompt_tokens])\n",
    "    max_prompt_size = max([len(t) for t in prompt_tokens])\n",
    "\n",
    "    total_len = min(params.max_seq_len, max_gen_len + max_prompt_size)\n",
    "    \n",
    "    tokens = torch.full((bsz, total_len), tokenizer.pad_id).to(device).long()\n",
    "    start_idx = len(prompt_tokens)\n",
    "    prev_idx = 0\n",
    "\n",
    "    for current_idx in range(start_idx, max_len):\n",
    "        concat_logits = model(prompt_tokens[prev_idx:current_idx], prev_idx)\n",
    "        # func_logits += self.logits_bias\n",
    "        if temperature > 0:\n",
    "            probs = torch.softmax(concat_logits, dim=-1)\n",
    "            next_token = sample_top_p(probs, top_p)\n",
    "        else:\n",
    "            next_token = torch.argmax(logits, dim=-1)\n",
    "\n",
    "        tokens[:, current_idx] = next_token\n",
    "        prev_idx = current_idx\n",
    "\n",
    "        if next_token >= 32000:\n",
    "            break\n",
    "        if next_token in stop_token:\n",
    "            break\n",
    "    return tokens, current_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f80f34-8b92-427c-bfb3-952a223df5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_toolken(generated_tokens, current_idx, tokenizer, func_dict):\n",
    "    decoded = []\n",
    "    for i, t in list(generated_tokens[:current_idx]):\n",
    "        try: decoded.append(tokenizer.decode(t))\n",
    "        except IndexError: pass\n",
    "        if t >= 32000: decoded.append(f'{[k for k,v in func_dict.items() if v == t-32000][0]}(')\n",
    "    return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2723eb9-4cab-458f-92b8-a9b1a6643726",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_args(cur_generation, func):\n",
    "    \"\"\"Converts raw argument formats from LLM to a list of arguments [x,y]\"\"\"\n",
    "    args = cur_generation.split(func)[-1].replace(\"=\", \"\").replace(\">\", \"\").replace(\"((\", \"(\").replace(\"))\", \")\")\n",
    "    args = args.replace(\"$\", \"\")\n",
    "    if \", \" in args:\n",
    "        args = args.replace(\", \", \";\").replace(\",\", \"\").replace(\";\", \", \")\n",
    "    args = args.replace(\" \", \"\")\n",
    "    if \"(\" not in args or \")\" not in args:\n",
    "            raise Exception(\"invalid args\")\n",
    "    if '%' in args:\n",
    "        temp = args.split(\"(\")[1].split(\")\")[0].split(\",\")\n",
    "        for arg_i, arg in enumerate(temp):\n",
    "            if \"%\" in arg:\n",
    "                arg = arg.replace(\"%\", \"\").strip()\n",
    "                arg = str(float(arg) / 100)\n",
    "            temp[arg_i] = arg\n",
    "        args = f\"({', '.join(temp)})\"\n",
    "    args = [int(x) for x in args.replace(\"(\", \"\").replace(\")\", \"\").split(',')]\n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb8d9aa-1b98-43c6-a19e-28cd6928dfdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def complete_function_call(model, current_generation, func, func_template):\n",
    "    # complete the arguments\n",
    "    func_prompt = func_template.replace('[QUESTION]', q) + current_generation\n",
    "    model.inference_mode = 'baseline'\n",
    "    generated_func_tokens = generate(model, func_prompt, temperature=temperature, top_p=top_p, max_len=max_len, stop_token=[29897, 3892])\n",
    "    current_generation += tokenizer.decode(list(generated_func_tokens))\n",
    "\n",
    "    # extract args and do function call\n",
    "    args = format_args(current_generation, func)\n",
    "    func_name = func[1:-1]\n",
    "    for f in func_list:\n",
    "        if f.__name__ == func_name: res = f(*args)\n",
    "    current_generation = current_generation.split(func)[0] + str(res)\n",
    "    return current_generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a556b8-37a8-49c9-af06-8af7ba00308f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(model:callable, prompt:str, tokenizer, func_template:str, func_dict:dict):\n",
    "    while True:\n",
    "        end_loop = True\n",
    "        \n",
    "        # generate up until the first toolken\n",
    "        model.inference_mode = 'func_embedding'\n",
    "        generated_tokens, current_idx = generate(model, prompt, temperature=temperature, top_p=top_p, max_len=max_len)\n",
    "        decoded = decode_toolken(generated_tokens, current_idx, tokenizer, func_dict)\n",
    "        current_generation = \"\".join(decoded)\n",
    "        \n",
    "        # \"tool mode\" — make function calls if present\n",
    "        for func in func_dict.keys():\n",
    "            if decoded[-1] == func + \"(\":\n",
    "                end_loop = False\n",
    "                complete_function_call(model, current_generation, func, func_template)\n",
    "        \n",
    "                # complete the generation\n",
    "                \n",
    "        if end_loop: break\n",
    "    return current_generation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "main_env",
   "language": "python",
   "name": "main_env"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
